\chapter{Stimuli Selection}
\label{ch:3}

\section{Introduction}

The current study aims to investigate native (L1) English speakers’ accentedness judgment on non-native (L2) English speech samples. To this end, 100 L2 audio speech samples served as stimuli for two perception studies. These two studies are discussed in Chapters 4 and 5. This chapter describes how the stimuli were selected. 

The 100 L2 speech samples were selected from the Speech Accent Archive (SAA: \citealp{Weinberger_saa_2019}). Audio samples in the SAA are phonetically transcribed by trained phoneticians using the International Phonetic Alphabet (i.e., IPA). These transcriptions reflect the transcribers’ perception. The 100 L2 speech samples were selected primarily based on their respective IPA transcriptions. Although care has been taken by the SAA personnel in providing relatively reliable transcriptions, inaccuracies could still exist. Therefore, the current study conducted acoustic analysis on the samples to further evaluate the reliability of the IPA transcriptions. 

In addition to the 100 L2 speech samples, speech samples from 50 L1 speakers of American English were also extracted from the SAA to evaluate the acoustic difference between L1 and L2 speech samples. Mean acoustic measurements of these 50 L1 speech samples were used as an approximation for native speaker norms. If the acoustic difference between an L2 speech segment and its native speaker norm could be captured by the IPA transcription for the L2 speech segment, then the IPA transcription is considered reliable and is used in the current study. 

Some of the acoustic measurements described in this chapter were further utilized in Experiment 2 (Chapter 5) to see how they correlate with perceived accentedness.  It should be noted that acoustic correlates of a phoneme are numerous and could vary depending on adjacent phonological contexts and sometimes extra-linguistic factors such as age \citep{Holt_2010}. Consequently, a few acoustic measurements cannot fully capture all of the features of a phoneme. To avoid the complexity of acoustics-to-phoneme mapping, the current study selected the stimuli primarily based on the IPA transcriptions, which are reflective of perception. The acoustic analysis described in this chapter serves mainly to verify the IPA transcriptions. The following section describes how stimuli selection and acoustic verification were carried out. 

\section{Corpus}

The 100 L2 stimuli are short two-word speech samples selected from the SAA. The SAA, as of June 2019, consists of 2786 audio speech samples produced by both L1 and L2 English speakers. All samples consist of speakers reading the sample paragraph given below:

\bigskip
\noindent \textbf{The ``Stella" Passage:}

\noindent \textit{Please call Stella. Ask her to bring these things with her from the store. Six spoons of fresh snow peas, five thick slabs of blue cheese, and maybe a snack for her brother Bob. We also need a small plastic snake, and a big toy frog for the kids. She can scoop these things into three red bags, and we will go meet her Wednesday at the train station.}
\bigskip

The speakers also provided their demographic information (e.g., age, gender, native language, age of English onset, learning style, current and former residence, etc.), which is publicly available on the SAA website. The speech samples were all digitally recorded by trained experimenters in the acoustic lab at George Mason University or somewhere else where the speakers and the experimenters deemed suitable. Only CD-quality (16-bit/44kHz) recordings are included in the archive. Low quality recordings are not accepted \citep{Weinberger_2011}.

The audio samples were narrowly transcribed using the IPA by at least three transcribers. The transcribers were phonetically trained graduate students at George Mason University. The IPA transcriptions were reached by the consensus of at least three people. All transcriptions were vetted and made available online by the administrator (i.e., Dr. Steven Weinberger) of the SAA. 

It should be mentioned that speech samples in the SAA were not transcribed by the same group of transcribers. Although most of the transcribers are L1 speakers of American English, some of them are international students whose native language is not English. Dr. Weinberger administered quality control by training all the transcribers through a semester-long, graduate-level phonetics class. Transcribers were instructed to follow the same guideline when transcribing the speech samples. To improve accuracy and resolve disagreements among the transcribers, speech processing software such as PRAAT \citep{Boersma_2015} or Audacity \citep{Mazzoni_2000} were often used to analyze benchmark acoustic signals. Around 1300 speech samples have been transcribed and are available online. An example is given below:

\bigskip
\noindent [pʰli:z kɔ:l stɛla ɛsk ɜ˞ tu bɹɪ̃ŋ ðɪ θɪ̃ŋs wɪθ hɜɹ fɹɔ̃m θə stɔ:ɹ sɪks ɪ̆spũ:nz ɔf fɹɛʃ snoʊ pʰi:z faɪf θɪk slɛ:bz̥ ɔv blu: tʃi:z ɛ̃n meɪbi ə snɛ̃:k fɔɹ hɛɹ bɹʌðəɹ bɑ:b̚ wi ɔlso nid̥ ə smɔ:l plɛ̞:stɪk sneɪk ɛ̃n ə bik t̪ɔɪ fɹɑ:ɡ fɔr ðə kɪ:ts ʃi kɛ̃n sku:p̺ ði:z θĩnks ɪ̃ntu θɹɪ ɹɪd bɛɡz ɛ̃n wi wɪl ɡoʊ mi:t hɛɹ wẽnɪzdeɪ æ d̪ə tɹeĩn steɪʃə̃n] (SAA: arabic23)
\bigskip

The vetted IPA transcriptions in the SAA were previously utilized by researchers in computational linguistics (e.g., \citealp{Frost_2013, Minematsu_2014}) and second language acquisition (e.g., \citealp{Klein_2011}). Recently, \citet{Weinberger_2019} recruited an additional 67 phonetically trained transcribers to transcribe a selection of audio clips from the archive. The results show that 72\% of the 67 participants’ transcriptions matched the vetted ones, lending support to the reliability of the vetted transcriptions. 

\section{Types of Stimuli}

The 100 L2 speech samples for the current study were selected based on the vetted transcriptions available in the SAA. These samples were further grouped into four types based how they differ from their L1 target productions. This section describes the determination of L1 target productions, and the four types of stimuli used by the current study.

\subsection{L1 Target Productions}

The L1 target productions were defined as the most common L1 productions. Such a treatment was based on the assumption that L1 American English listeners would all be familiar with the most common L1 productions and consequently rate them as native-like. To find the most common L1 productions, the current study surveyed productions from 100 L1 speakers of American English in the SAA (See Appendix A for demographic information). The most common productions among these speakers were considered L1 target productions. For example, 90\% of the L1 productions for the word ``\textit{thick}" are [θɪk]. [θɪk] was therefore chosen as the L1 target production for “\textit{thick}.” IPA transcriptions of these L1 American English speakers were also used to build a computational model to approximate English phonetic and phonological grammar. Chapter 6 discusses the model in detail.

For the two perception experiments, the current study selected 100 L2 speech samples as stimuli. L2 speech samples that were transcribed the same as their L1 target production (e.g., [θɪk] for ``\textit{thick}") were termed the “match” stimuli, meaning that the L2 productions match their L1 target productions. L2 productions that do not match their L1 target productions were termed the “mismatch” stimuli.  Some of the mismatch stimuli are not unique to L2 speakers of English. For example, some L1 speakers pronounce ``\textit{thick}" as [tɪk] according to data on the SAA. Since [tɪk] does not match the L1 target [θɪk],  [tɪk] was nevertheless termed as a mismatch stimulus. Presumably, the mismatch stimuli that are observed in L1 speech data would be judged as less accented. The “mismatch” that are not observed in L1 speech data (e.g., pronouncing “\textit{ask}” as [æskə]) would be judged as more accented. 


\subsection{Four Types of Stimuli}

The mismatch stimuli were further divided into three groups based on three types of mismatches, namely, stimuli with consonant mismatches (e.g., [tɪk] for “\textit{thick}”), stimuli with vowel mismatches (e.g., [θik] for “\textit{thick}”), and stimuli with syllable structure mismatches (e.g., [faɪvə] for “\textit{five}”). Therefore, the 100 stimuli were divided into four types (i.e., the match type and the three types of mismatches). 

Table \ref{table:tos} illustrates the four types of stimuli. IPA transcriptions in the match stimuli column represent the most common L1 pronunciations for the five phonological contexts. 25 of the 100 L2 stimuli were transcribed the same as the IPA transcriptions listed in the match column. These 25 L2 speech samples were called the match stimuli \footnote{[æsk (h)əɹ] in the match column means that both [æsk əɹ] and [æsk həɹ] are equally common in the SAA.}. The remaining 75 are mismatch stimuli. They differ from the match stimuli by only one phonetic element. For example, stimulus [faɪv tɪk] differs from its corresponding match stimulus [faɪv θɪk] by only one consonant (i.e., [θ]$\rightarrow$[t]). Stimulus [faɪv tɪk] therefore contains only one consonant mismatch. Among the 75 mismatch stimuli, 25 contain only one consonant mismatch (five stimuli for each context), 25 contain only one vowel mismatch (five stimuli for each context), and 25 contain only one syllable structure mismatch (five stimuli for each context). 

\begin{table}[!h]
  \figSpace
  \centering
  \caption{Types of Stimuli}
\label{table:tos}
    \begin{tabular}{p{5.2em}llll}
    \toprule
    Context & \multicolumn{1}{p{5.2em}}{Match} & \multicolumn{1}{p{5em}}{Consonant\quad Mismatch} & \multicolumn{1}{p{5em}}{Vowel\quad Mismatch} & \multicolumn{1}{p{5em}}{Syllable Mismatch} \\
    \midrule
    \textit{please call} &[pʰliz kʰɑl] &[\textbf{p}liz kʰɑl]&[pʰliz kʰ\textbf{o}l]&[pʰ\textbf{ə}liz kʰɑlˠ]\\
        \textit{ask her} &[æsk (h)əɹ] &[æsk hə\textbf{r}]&[\textbf{ɑ}sk həɹ]&[æs\underline{ } həɹ]\\
        \textit{six spoons} &[sɪks spunz] &[sɪks spun\textbf{ʃ}]&[s\textbf{i}ks spunz]&[sɪks \textbf{ə}spunz]\\
        \textit{five thick} &[faɪv θɪk]&[faɪv \textbf{t}ɪk] &[f\textbf{a}v θɪk]&[faɪv\textbf{ə} θɪk]\\
        \textit{small plastic} &[smɑl pʰlæstɪk]&[smɑ\textbf{ɭ} pʰlæstɪk]&[smɑl pʰlæst\textbf{i}k]&[smɑl pʰlæs\underline{ }ɪk] \\
    \bottomrule
    \end{tabular}%
    \figSpace
\end{table}%

\section{Acoustic Comparisons}

The 100 L2 stimuli represented 11 types of consonant mismatches, five types of vowel mismatches and two types of syllable structure mismatches. The stimuli were chosen mainly based on the IPA transcriptions available in the SAA. In order to verify the IPA transcriptions, acoustic analyses were carried out to compare benchmark measurements between the L1 and L2 speech samples. The aim of the following acoustic analysis is to verify whether acoustic differences between an L2 stimulus and its corresponding L1 speech samples can be captured by the IPA transcription of the L2 stimulus. For example, if an L2 segment was transcribed as an aspirated [pʰ], while its corresponding L1 productions are the non-aspirated [p]s. The [ʰ] symbols suggests that the L2 segment has a longer voice onset time (VOT) than the L1 [p]s. To verify whether the [pʰ] was correctly transcribed, the current study measures the duration of the L2 VOT and the mean VOT of L1 [p]s. If the L2 VOT is indeed longer than the mean L1 VOT, then the current study accepts [pʰ] as a correct transcription for the L2 segment.  

L1 English speech samples from the SAA were selected for the determination of what might constitute native speaker pronunciation norms. The speech samples were produced by 50 L1 speakers of American English. They were from 21 states in the continental U.S., ages from 18 to 79 (M=39.67, SD=16.62). 25 of them are male, the other 25 are female. Detailed demographic information of these 50 L1 speakers is listed in Appendix A.  

A large body of previous research has demonstrated that phonemic categories are distinguished
by multiple acoustic cues (e.g., Lisker, 1986; Toscano and McMurray, 2010). For example, VOT, pitch of the following vowel, and other 14 kinds of acoustic cues could be responsible for the distinction between /pa/ and /ba/ (Lisker, 1986). The current study opts to focus on the primary and most robust cues as identified by previous speech perception research, while fully acknowledging that other phonetic cues could also affect speech perception.


\subsection{Segmentation}

All the L1 and L2 speech samples were first segmented. The intensity of the speech samples was normalized to 75dB using PRAAT. Initial phoneme segmentation of the speech samples was performed with the Montreal Forced Aligner \citep{McAuliffe_2017}. This is a newly developed neural network-based aligner that is comparable to human annotators and provides better performance than the traditional Penn Phonetics Lab Forced Aligner \citep{Yuan_2008}. Errors or inaccuracies discovered in the auto-segmentation were manually corrected. Relevant acoustic measurements were extracted via a PRAAT script for further analysis. Figure \ref{fig:seg} illustrates the results of the automated alignment, where the top row displays information of the spectrogram and formants and the second row from the top displays pitch (dotted line) and intensity (solid line) contours. The third row from the top represents phone boundaries using the Arpabet symbols and the bottom row shows word boundaries.

\begin{figure}[ht]
  \figSpace
    \centering
	\includegraphics[width=0.8\textwidth]{figures/seg.eps}
    \caption{Illustration of Auto-segmentation}
    \label{fig:seg}
  \figSpace
\end{figure}

\subsection{Plosives}

Six L2 speech samples selected by the current study contained plosive-related mismatches as indicated by their respective IPA transcriptions. The following describes how the mismatches were verified by acoustic measurements. Duration of voice onset time (VOT) was used as the benchmark acoustic measurement for plosives. VOT duration of L2 segments and mean VOT duration of L1 segments were measured. 

VOT is defined as the interval between the onset of a plosive burst and the onset of the following vocalic onset. There are numerous claims that VOT directly affects accentedness perception \citep{Major_1987, Riney_1999}. Six L2 stimuli were therefore selected to verify these claims made in previous research. Following the practice of \citet{Chodroff_2017}, the beginning of the VOT was placed at the beginning of a plosive burst release; and the endpoint was placed at the beginning of periodicity in the waveform or a visible pitch track, whichever came first. VOT labeling was initially achieved in PRAAT with the AutoVOT plugin \citep{Keshet_2014}. Labeling errors were manually corrected in PRAAT based on waveforms and spectrograms. 

Contexts “\textit{please call},” “\textit{small plastic}” and “\textit{six spoons}” were used for the investigation of VOT-related consonant mismatches. Six L2 speech samples that were identified as having VOT-related mismatches were extracted for analysis. Two speech samples involved VOT-shortening on [kʰ] in the word “call,” one speech sample involves VOT-shortening on [pʰ] in the word “please,” one speech sample involves VOT-shortening on [pʰ] in the word “\textit{plastic},” two speech sample involve VOT-lengthening on [p] in the word “\textit{spoons}.” In addition to the L2 speech samples, VOTs of 50 L1 speech samples were measured for comparison. 

Table \ref{table:vot} illustrates the type of VOT-related consonant mismatches and the contexts where they occurred. Every row in Table \ref{table:vot} represents the VOT of a plosive segment. The mismatch column lists the type of VOT-related mismatches and the segments involved. The L2 VOT column contains durational measurements of the six L2 VOTs. L2 VOTs were converted to z-scores with regard to L1 English VOT means and standard deviations (SD). A z-score represents how many standard deviations an L2 VOT mean is from the mean L1 VOTs. A positive z-score means an L2 VOT is longer than the mean L1 VOT, while a negative z-score means an L2 VOT is shorter than the mean L1 VOT.

For example, the first row of Table \ref{table:vot} shows that an L2 stimulus “\textit{please call}” involves the de-aspiration of [kʰ] in the word “call.” The L2 segment [k] has a VOT of 33.01 milliseconds (ms). Calculation based on 50 L1 American English productions of “\textit{please call}” shows that the mean VOT of L1 [kʰ]s is 52.78 ms with a standard deviation of 13.71 ms. The z-score shows that the L2 VOT is 1.44 standard deviations below the L1 mean. 

\begin{table}[!h]
  \figSpace
  \centering
  \caption{L1 and L2 VOT Comparisons}
\label{table:vot}
    \begin{tabular}{llrrr}
    \toprule
   Contexts & Mismatches & L2 VOT (ms) & L1 (English) VOT (ms) & Z \\
    \midrule
    \textit{please call} & [kʰ]$\rightarrow$[k] & 33.01 & M=52.78; SD=13.71 & -1.44 \\
    \textit{please call} & [kʰ]$\rightarrow$[k] & 21.26 & M=52.78; SD=13.71 & -2.30 \\
    \textit{please call} & [pʰ]$\rightarrow$[p] & 10.05 & M=62.50; SD=18.06 & -2.91 \\
    \textit{small plastic} & [pʰ]$\rightarrow$[p] & 20.86 & M=62.84; SD=15.53 & -2.70 \\
    \textit{six spoons} & [p]$\rightarrow$[pʰ] & 45.33 & M=14.46; SD=7.15 & +4.32 \\
    \textit{six spoons} & [p]$\rightarrow$[pʰ] & 68.53 & M=14.46; SD=7.15 & +7.56 \\
    \bottomrule
    \end{tabular}%
  \figSpace
\end{table}%


As shown in Table 3.2, the shortened VOTs are indeed shorter than the L1 means, while the lengthened VOTs are indeed longer than the L1 means. Therefore, VOT differences between the L1 and L2 speech samples were successfully captured by the IPA transcriptions of the L2 speech sam- ples. These L2 speech samples were therefore chosen to represent VOT-related phonetic mismatches in L2 speech.

\subsection{Fricatives} 

Seven L2 stimuli were selected to investigate the perceptual accentedness of fricative-related mismatches. Four stimuli involve replacing L1 fricatives with other fricatives (e.g., [z]$\rightarrow$[s], [θ]$\rightarrow$[f]). Three stimuli involve replacing the interdental fricative /θ/ with /t/. The seven stimuli are listed in Table \ref{table:cog}. Analysis in this session concerns three types of benchmark acoustic signals, namely, Center of Gravity, pitch context, and noise ratio. These acoustic signals were selected to approximate differences in place and manner of articulation.

\subsubsection{Center of Gravity}

Previous research on the acoustic correlates of English fricatives has discovered that the Center of Gravity (COG) of fricatives is a reliable cue for place of articulation \citep{Jongman_2000}. COG is a measurement of energy concentration. Energy of a speech sound, as measured by amplitude, could be concentrated in either the higher frequencies or the lower frequencies of the sound. A smaller COG implies that the energy of a sound is concentrated in the lower frequencies. 

As a measurement for place of articulation, COG value decreases as place of articulation moves further back in the oral cavity. For example, alveolar fricatives (e.g., /s/ and /z/) have lower COGs than dental fricatives (e.g., /θ/ and /ð/), whose COGs are lower than labiodental fricatives (e.g., /f/ and /v/) (Jongman et al., 2000). Although COG is traditionally thought of as a cue for place of articulation, \citet{Jongman_2000} reported that COG is also a good indicator for voicing, with voiceless English fricatives having significantly higher COGs than their voiced counterparts. Table \ref{table:cog} lists the COGs of segments in the seven L2 and L1 stimuli selected by the current study.

% Table generated by Excel2LaTeX from sheet 'cog'
\begin{table}[h]
  \figSpace
  \centering
  \caption{L1 and L2 COG Comparisons}
\label{table:cog}
    \begin{tabular}{llrlr}
    \toprule
    Contexts & Mismatches & L2 COG (Semitone) & L1 COG (Semitone)&Z \\
    \midrule
    \textit{please call} & [z]$\rightarrow$[s] & 77.68 & M=71.14; SD=5.31 & +1.23 \\
    \textit{small plastic} & [s]$\rightarrow$[z] & 64.39 & M=71.30; SD=7.28 & -0.95 \\
    \textit{five thick} & [θ]$\rightarrow$[f] & 73.77 & M=64.37; SD=11.40 & +0.82 \\
    \textit{six spoons} & [z]$\rightarrow$[ʃ] & 71.10  & M=64.56; SD=8.86 & +0.73 \\
\textit{five thick}& [θ]$\rightarrow$[t̪] & 59.63 & M=64.37; SD=11.40 & -0.42 \\
\textit{five thick}& [θ]$\rightarrow$[t̪] & 63.27 & M=64.37; SD=11.40 & -0.10 \\
  \textit{five thick}& [θ]$\rightarrow$[t̪] & 42.63 & M=64.86; SD=9.71 & -2.29 \\
    \bottomrule
    \end{tabular}%
  \figSpace
\end{table}%

Every row of Table \ref{table:cog} shows the COGs of an L2 segment and the corresponding mean L1 COG value. For example, the first L2 stimulus is “\textit{please call}.” The coda of “\textit{please}” was transcribed as [s]. The L2 production therefore involves the devoicing of the [z] in “\textit{please}” (i.e., [z]$\rightarrow$[s]). The COG of the L2 segment [s] is 77.68 semitones, while its corresponding L1 segment [z] has a mean COG of 71.14 semitones with a standard deviation of 5.31. The L2 segment [s] is thus 1.23 standard deviations above the mean. This result is consistent with previous claims that COGs of voiceless fricatives are higher than COGs of their voiced counterparts. Therefore, the [s] was accepted by the current study as a correct transcription.

The second L2 stimulus “\textit{small plastic}” replaced the [s] in “\textit{small}” with a voiced [z]. The COG of this L2 segment [z] is lower than the mean COG of the corresponding L1 [s]s. This finding is also consistent with previous research, which showed that voiced fricatives have lower COGs than voiceless fricatives \citep{Jongman_2000}. Acoustic measurements for the third stimulus  show that the L2 segment [f] has a higher COG than its L1 target segment /θ/, which is consistent with previous findings that COG value increases as the place of articulation moves further front in the oral cavity \citep{Jongman_2000}. Given these results, the IPA transcriptions for the first three stimuli in Table \ref{table:cog} were considered accurate by the current study. The difference between the remaining four L2 stimuli and their corresponding L1 productions cannot be explained via the COG measurement. The following section discusses two additional acoustic measurements that could capture the difference between the remaining four L2 stimuli and their corresponding L1 productions.  

\subsubsection{Pitch Context}

The fourth L2 stimulus “\textit{six spoons}” changed the final consonant in “\textit{spoons}” from [z] to [ʃ]. The COG of the voiceless L2 segment [ʃ] is higher than the mean COG of its target L1 segment [z]. Previous research claimed that the COG of the post-alveolar fricative [ʃ] should be lower than both alveolar fricatives /s/ and /z/ \citep{Jongman_2000}. Based on the COG measurement, [ʃ] is perhaps not a correct transcription. However, acoustic correlates of English phonemes are multidimensional. COG values alone cannot explain why the final consonant of “\textit{spoons}” was transcribed as [ʃ]. 

In addition to COG values. the perception of /s/ and /ʃ/ could be affected by the pitch values of the preceding segments \citep{Niebuhr_2017}. Specifically, /s/ is more likely to be perceived as /ʃ/ when its preceding segment carries a higher pitch. In other words, the final consonant in “\textit{spoons}” could be an /s/, but was perceived and transcribed as [ʃ] because the penultimate segment /n/ carries a relatively higher pitch. To investigate whether the preceding pitch context of the final consonant in “\textit{spoons}” potentially affected transcribers’ perceptions, pitch values of the /n/s were extracted in PRAAT. Pitch values were extracted at the location of the energy peak in the amplitude spectrum, using methods described in \citet{De_Jong_2009}. Pitch values were converted to semitones relative to 100 Hertz to approximate the non-linear mapping between Hertz values and human perception. 

The L2 stimulus “\textit{six spoons}” was produced by a male Lamaholot speaker. The [n] of the L2 stimulus carries a pitch of 20.98 semitones. To calculate pitch values of the natively produced /n/s, productions of 25 male L1 American English speakers were similarly processed in PRAAT. Results showed L1 male speakers’ productions of the /n/ carry a mean pitch of 14.93 semitones, with the standard deviation of 3.27 semitones. The L2 /n/ thus indeed carries a relatively higher pitch than mean pitch values of the L1 /n/s. Therefore, there is a reason to believe that the pitch value of the penultimate consonant [n] in the L2 production of “\textit{spoons}” affected transcribers’ perception of the final consonant. This finding does not necessarily imply that the IPA transcriptions of the L2 stimulus are incorrect, but affirms the fact that acoustic correlates of phonemes are multidimensional. Therefore, the current study accepted the [ʃ] as a correct transcription.

\subsubsection{Noise Ratio}

In addition to the four stimuli analyzed above, there are three stimuli that involve the replacement of the dental fricative /θ/ with a dentalized [t̪]. As discussed above, COGs increase as the place of articulation moves farther front in the oral cavity. Therefore, dental [θ]s should have higher COGs than [t̪]s. Table \ref{table:cog} shows that the mean L1 COG of [θ]s is indeed higher than COGs of the [t̪]s. However, the difference between /θ/ and /t/ lies primarily on their respective manners of articulation, which is not captured by COG measurements. To inspect whether the [t̪]s are reliable transcriptions, the current study opted to use noise ratio to investigate the manner difference between fricative and plosive consonants.

Plosive consonants, such as the alveolar /t/, consist of a silent closure interval, which is followed by a frication noise burst and an interval of aspiration noise. Fricative consonants, such as /θ/, also consist of a silent closure interval, which is followed by a period of friction noise. The longer the closure interval, the more likely a fricative is perceived as an affricate \citep{Dorman_1980}. The shorter the duration of friction noise, the more likely a fricative is perceived as a plosive \citep{Dorman_1980}. 

To investigate durational measurements of the American English /θ/, the same 50 American English speakers’ productions of “\textit{five thick}” were used. Male and female samples were analyzed separately, because frication noise of females tends to be shorter than males \citep{Jongman_2000}. 

A possible confounding factor of durational measurements is speech rate. Intervals of closure and frication noise might be shortened in fast speech. In slow speech, the intervals could be lengthened. To control for speech rate, noise ratios were calculated. Noise ratios were defined as the ratio of fricative noise duration over the duration of the whole word \citep{Jongman_2000}. Word duration was defined as the interval between the onset of the frication to the end of the word. Closure intervals were not included in the total duration of a word, because the L1 and L2 segments are word initial. It is difficult to distinguish closure intervals of word-initial segments from speech pauses between words. Tabel \ref{table:nr} illustrates the noise ratios of the L1 and L2 segments.

% Table generated by Excel2LaTeX from sheet 'noise'
\begin{table}[!h]
  \figSpace
  \centering
  \caption{L1 and L2 Noise Ratio Comparisons}
\label{table:nr}
    \begin{tabular}{lllrr}
    \toprule
    Phrases & Gender & Mismatches & L2 Noise Ratio & L1 Noise Ratio \\
    \midrule
    \textit{five thick} & male  &  [θ]$\rightarrow$[t̪] & 0.17  & 0.25 \\
   \textit{five thick} & male  & [θ]$\rightarrow$[t̪] & 0.15  & 0.25 \\
   \textit{five thick} & female & [θ]$\rightarrow$[t̪] & 0.16  & 0.20 \\
    \bottomrule
    \end{tabular}%
  \figSpace
\end{table}%

The mean noise ratio for male L1 speakers is 0.25 (SD=0.06), and the mean noise ratio for female L1 speakers is 0.20 (SD=0.08). For the three L2 stimuli that replaced /θ/ with [t] or [t̪], noise durations were defined as the duration of the release burst and the aspiration noise. Word durations were defined as the interval from the onset of the release burst to the end of a word. As shown in Table \ref{table:nr}, the noise ratios for [t̪]s are 0.17, 0.15, and 0.16 respectively. In other words, L1 [θ]s, in general, have a longer frication noise duration than the noise durations (i.e. burst and aspiration noise) of the three corresponding L2 segments. Since shorter noise duration of a segment increases the chance for it to be perceived as a plosive consonant \citep{Jongman_1989}, there is reason to believe that the three L2 segments were transcribed correctly. These L2 stimuli were therefore accepted by the current study as representatives of /θ/-stopping (i.e., /θ/$\rightarrow$/t/). 

\subsection{Liquids}

In addition to plosives and fricatives, the current study also aims to investigate the accentedness of liquid productions in L2 speech. L2 speech involving the alternation between /ɹ/ and /l/ was often perceived by L1 American English listeners as very accented \citep{Riney_2005}. Eight L2 speech samples were selected to investigate the accentedness of syllable final /l/s and /ɹ/s. Based on findings in previous research, the degree of /l/-velarization was approximated by the difference between F1 and F2 \citep{Riney_2005} values. The degree of /ɹ/-rhoticity was approximated by the difference between F2 and the third formant frequencies (F3) \citep{Ohala_2001}. The F1, F2, and F2 values were extracted at the energy peak in the amplitude spectrum of the liquids.The following section discusses the analysis on L1 and L2 liquid productions in the phonological contexts of “\textit{small plastic}” and “\textit{ask her}.”

\subsubsection{Formant Information of L1 Liquids}

Previous acoustic research has shown that the velarization of the English word-final /l/ causes an increase in F1 and a decrease in F2, with respect to non-velarized /l/s \citep{Riney_2005}. Previous literature on world-final /ɹ/ often associates rhoticity with the lowering of F3. In addition to the English  /ɹ/s, low F3 for rhoticity was shown to hold for Malayalam rhotic trills, Toda trills, Tamil retroflex /ɭ/ and Hindi retroflex plosives \citep{Ohala_2001}. Indeed, the difference between F2 and F3 has been recommended as a reliable acoustic cue for automated measurement of rhotics \citep{Campbell_2018}. The current study therefore operationalized rhoticity by taking the difference between F2 and F3. 

The labeling of liquid segments was achieved via the Montreal Forced Aligner with manual adjustments afterwards. The beginning of a word-final liquid was set at the start of the F2 transition, while the end of a word-final liquid was set at the beginning of a pause between words or the following segment (whichever occurred first). F1, F2 and F3 values of each liquid were then extracted with PRAAT at the location of the energy peak in the amplitude spectrum, using methods described in \citep{De_Jong_2009}. Formant frequencies were then converted to semitones relative to 100 Hertz. 

Figure \ref{fig:l1_liquid} demonstrates the spectral information of word-final /l/s and /ɹ/s produced by the 50 native speakers of American English, where the bold phonetic symbols represent the means and the shaded areas represent one standard deviation around the means. The small gray symbols represent productions of the 50 native speakers of American English. Male and female productions were presented separately, because male voice frequencies are generally lower than female voice frequencies. In general, the /ɹ/s show a relatively smaller F3-F2 difference, demonstrating that the English word-final /ɹ/s are more rhotic than word-final /l/s. The word-final /l/s show a relatively small F2-F1 difference, demonstrating that the word-final /l/s have a higher degree of velarization than word-final /ɹ/s. 

\begin{figure}[h]
  \figSpace
    \centering
        \input{figures/chp3/liq1.tex}
	%\includegraphics[width=0.75\textwidth]{figures/liquids_native.png}
    \caption{Formant Information of L1 Liquids}
    \label{fig:l1_liquid}
  \figSpace
\end{figure}

\subsubsection{Formant Information of L2 Liquids}

Eight L2 speech samples were selected based on the vetted transcriptions, five of which involved the replacing of English word-final /ɹ/ with a trill /r/; the remaining three were /l/-related variations: two of the three replaced English word-final /l/ with a retroflexed /ɭ/, the third replaced /l/ with a flap /ɾ/. Labeling of L2 segments followed the same method as mentioned above. F1, F2, and F3 values were similarly extracted with PRAAT. Figure \ref{fig:l2_liquid} demonstrates the spectral information of both the L1 and L2 segments, while the phonetic symbols with a gray background represent L1 segments and the phonetic symbol without background represent the eight L2 segments. 

As Figure \ref{fig:l2_liquid} shows, both of the retroflexed [ɭ]s have a relatively smaller F3-F2 difference than English [l]s, showing that the [ɭ]s are likely to be more rhotic than their L1 counterparts. The L2 /r/s, on the other hand, have a relatively larger F3-F2 difference than the L1 /ɹ/s, showing that the L2 /r/s are less rhotic than their L1 counterparts. The eight L2 speech samples were therefore considered as correctly transcribed. They were consequently chosen to represent L2 liquid mismatches.

\begin{figure}[h]
  \figSpace
    \centering
            \input{figures/chp3/liq2.tex}
%\includegraphics[width=0.75\textwidth]{figures/liquids_nonnative.png}
    \caption{Formant Information of L2 Liquids}
    \label{fig:l2_liquid}
  \figSpace
\end{figure}

\subsection{Vowels}

Labeling of vowels was done in PRAAT. The transitioning periods in and out of a vowel were included in the label. Following methods described in \citet{De_Jong_2009}, F1 and F2 values were estimated at the location of the energy peak in the amplitude spectrum of a vowel. Female spectral information was extracted at a pitch range from 100 Hz to 500 Hz, with the maximum frequency set at 5500 Hz. Male spectral information was extracted at a pitch range from 75 Hz to 300 Hz, with the maximum frequency set at 5000 Hz. Formant frequency Hertz values were converted to semitones relative to 100 Hz. 

Since formant frequencies of a vowel vary considerably depending on the adjacent phonological context, the comparisons between L1 and L2 vowel productions were therefore carried out in each phonological context. The following sections focus mainly on vowel space, a two-dimensional area bounded by lines connecting the F1 and F2 coordinates of a vowel. F1 and F2 values are inversely related to vowel height and vowel frontness. Prosodic elements such as vowel intensity, pitch contour and vowel duration are not discussed. 

\subsubsection{Context 1: “\textit{ask her}”}

According to data in the SAA, the most common L1 production for “\textit{ask}” is [æsk], which was considered by the current study as the L1 target production. L2 speech samples that were transcribed as [æsk] were termed as the match stimuli. L2 speech samples that were not transcribed as [æsk] were the mismatch stimuli. The current study selected five L2 speech samples that contain vowel mismatches. These L2 speech samples were transcribed as [æ̞sk həɹ] (i.e., vowel lowering), [æ̝sk  həɹ] (i.e., vowel raising), [ɑsk həɹ] (i.e., vowel backing), and two incidences of [a:sk həɹ] (i.e., vowel lowering and lengthening).

To evaluate whether these IPA transcriptions are reliable, F1 and F2 values were extracted in the manner described above. Figure \ref{fig:ask} illustrates the formant frequencies of the 50 L1 and the five L2 productions of /æ/, where the F2 values represent vowel frontness and the F1 values represent vowel height. The /æ/s in gray squares represent mean values of L1 productions. The small gray symbols represent the 50 L1 speakers’ productions. The five large emboldened symbols represent the five L2  productions of /æ/. 

\begin{figure}[h]
  \figSpace
    \centering
    \input{figures/chp3/askher.tex}
%\includegraphics[width=0.75\textwidth]{figures/chp3/askher.eps}
    \caption{Formant Comparison between L1 and L2 Vowels in “\textit{ask her}”}
    \label{fig:ask}
  \figSpace
\end{figure}

Figure \ref{fig:ask} shows that the vetted transcriptions are generally accurate in describing the L2 segments. Discrepancies, however, do exist between the current production analysis and the transcribers’ perception. Spectral information indicates that the L1 /æ/s are more front than all the L2 productions. Therefore, the difference between the L1 [æ]s and the L2 [a]s, should lie in the frontness of the vowel, rather than the height. Despite the discrepancies, all the L2 vowels are at least one standard deviation apart from the L1 means (i.e., the shaded area), showing that the L2 vowels are very likely to be different from the L1 target production /æ/. Transcriptions of the five L2 stimuli were accepted by the current study as representations of vowel mismatch. The two L2 [a]s were considered a problem of vowel backing, rather than vowel lowering.

\subsubsection{Context 2: “\textit{small plastic}”}

In the context “\textit{small plastic},” three types of vowel mismatches were investigated, namely vowel raising, vowel fronting and vowel lowering. Two L2 speech samples were selected to represent the raising of [ɑ] in “\textit{small}.” The two L2 vowels for  [ɑ] were transcribed as [o] and [ɔ]. The L1 target production for “plastic” was determined as [pʰlæstɪk]. One L2 speech sample was chosen to represent the fronting or the tensing of [ɪ]. The L2 vowel for [ɪ] was transcribed as [i]. Two other L2  speech samples represent the lowering of [æ] in “\textit{plastic}.” These two L2 vowels were transcribed as [a] and [a̝]. Figure \ref{fig:small} illustrates the formant information of the L1 and L2 segments. 

\begin{figure}[h]
  \figSpace
    \centering
    \input{figures/chp3/smallplastic.tex}
	%\includegraphics[width=0.75\textwidth]{figures/chp3/smallplastic.png}
    \caption{Formant Comparison between L1 and L2 Vowels in “\textit{small plastic}”}
    \label{fig:small}
  \figSpace
\end{figure}

Figure \ref{fig:small} illustrates that the IPA transcriptions for L2 segments are accurate in describing formant information of the L2 segments. These five L2 speech samples were therefore chosen to represent vowel raising, vowel fronting, and vowel lowering in the context of “\textit{small plastic}.” 

\subsubsection{Context 3: “\textit{please call}”}

In the context of “\textit{please call},”  five L2 speech samples were chosen to represent the raising of /ɑ/. Only the productions of the vowel /ɑ/ in “\textit{call}” were investigated. The five L2 productions of the vowel /i/ in ``\textit{please}" were all transcribed as [i], which matches transcriptions of the match stimuli. Therefore, analysis in this section focuses only on the vowel in “\textit{call}”. Formant frequencies of L1 and L2 vowels are plotted in Figure \ref{fig:call}, where the two large emboldened /ɑ/s epresent the L1 mean values. The small gray symbols represent the 50 L1 speakers’ productions of /ɑ/. The [ɔ]s and [o]s represent the five L2 productions of /ɑ/. Figure \ref{fig:call} shows that the L2 vowels for /ɑ/ are indeed more back and higher than the L1 norms. 

\begin{figure}[h]
  \figSpace
    \centering
     \input{figures/chp3/pleasecall.tex}
	%\includegraphics[width=0.75\textwidth]{figures/chp3/pleasecall.png}
    \caption{Formant Comparison between L1 and L2 Vowels in “\textit{call}”}
    \label{fig:call}
  \figSpace
\end{figure}

\subsubsection{Context 4: “\textit{five thick}”}

Five L2 speech samples were chosen to investigate the vowels in the context of “\textit{five thick},” three of which contain L2 vowels for the lax vowel /ɪ/ in “\textit{thick},” while the remaining two contain L2 vowels for the diphthong /aɪ/ in “\textit{five}.” Figure \ref{fig:five} demonstrates the vowel space of the L1 and L2 vowels. Four of the five L2 vowels are at least one standard deviation away from the L1 means. The fifth L2 vowel was transcribed as [a], and its vowel space is very close to the L1 mean of /aɪ/. 

The SAA classified the L2 [a] as a shortened L2 variation of the L1 [aɪ]s. The difference between [a] and [aɪ] is that [aɪ] contains an off-glide, which requires the raising of the tongue near the end of the articulation. The English [aɪ] is a falling diphthong, which starts with a segment that carries higher prosodic prominence (i.e., higher pitch and/or loudness) and ends in an off-glide that carries less prominence. As mentioned above, the current study opted to extract F1 and F2 values at the spectral peak of a vowel. The vowel space of [aɪ] illustrated in Figure \ref{fig:five}, therefore, mainly shows the vowel space of the [a] in [aɪ], which is normally where the spectral peak is located. Therefore, the F2 and F1 values extracted by the current study cannot successfully distinguish [aɪ] from its L2 segment [a].  

\begin{figure}[h]
  \figSpace
    \centering
    \input{figures/chp3/fivethick.tex}
  %\includegraphics[width=0.75\textwidth]{figures/chp3/fivethick.png}
    \caption{Formant Comparison between L1 and L2 Vowels in “\textit{five thick}”}
    \label{fig:five}
  \figSpace
\end{figure}

The [a] was produced by a Mandarin speaker. The [ɑɪ] was produced by a German speaker. To measure the dynamic spectral difference between [aɪ] and [a] in the environment of  “\textit{five},” dynamic spectral information needs to be investigated. Since [ɪ] is more front and higher than [a], an F1 decrease and an F2 increase is expected toward the end of [aɪ]. F1 and F2 contours of the L2 vowel [a] would remain relatively flat. Since [ɑɪ] starts with a back vowel [ɑ] and ends in an off-glide, an F2 increase would be expected. However, since [ɑɪ] starts with a back vowel [ɑ], F2 values of [ɑɪ] should be, in general, lower than F2 values of [aɪ]. 

To evaluate the dynamic spectral difference between the L1 diphthong /aɪ/ and its two L2 counterparts (i.e. [a] and [ɑɪ]), F1 and F2 contours for each L1 [aɪ] were extracted using PRAAT. The contours were then divided into 10 equally spaced time points, from which F1 and F2 values were extracted and converted to semitones relative to 100 Hz. Smoothing Spline ANOVA (SSANOVA) was implemented on the F1 and F2 contours of L1 [aɪ]s using the \textit{gss} package in R \citep{Gu_2013} with 95\% Bayesian confidence intervals. 

\begin{figure}[h]
  \figSpace
    \centering
    \input{figures/chp3/five_ay.tex}
%\includegraphics[width=0.75\textwidth]{figures/five_ay.png}
    \caption{Dynamic Formant Comparisons between L1 and L2 Vowels in “Five”}
    \label{fig:ay}
  \figSpace
\end{figure}

F1 and F2 contours for the Mandarin speaker's [a] and the German speaker's [ɑɪ] were similarly extracted. Figure \ref{fig:ay} shows the F1 and F2 contours of L1 English [aɪ]s and the L2 vowels [ɑɪ] and [a] \footnote{\noindent Note: Both the German and Mandarin speakers are male. The “English” contours represent mean values of 25 male L1 speakers.} Contours on the top represent F2 changes across 10 time points, while the contours on the bottom represent F1 changes across 10 time points. As expected, the L1 [aɪ] exhibits a rising F2 contour, while the L2 vowel [a] shows a relatively flat F2 contour. The L2 vowel [ɑɪ] also exhibits a rising F2 contour. Its general F2 values, however, are lower than the L1 [aɪ]s, showing that L2 [ɑɪ] are indeed more back than [aɪ]s. These results show that the IPA transcriptions for the two L2 vowels have successfully captured the spectral differences between the two L2 vowels and their corresponding L1 productions. These two L2 speech samples were accepted as representations for off-glide deletion and vowel backing in the context of ``\textit{five thick}."

\subsubsection{Context 5: “\textit{six spoons}”}

\begin{figure}[h!]
  \figSpace
    \centering
    \input{figures/chp3/sixspoons.tex}
% \includegraphics[width=0.75\textwidth]{figures/chp3/sixspoons.png}
    \caption{Formant Comparison between L1 and L2 Vowels in “\textit{six spoons}”}
    \label{fig:six}
  \figSpace
\end{figure}

Five L2 speech samples were selected for the investigations of [ɪ] and [ũ] in “\textit{six spoons},” three of which represent the tensing or fronting of [ɪ] to [i], two represent the raising or de-nasalization of [ũ]. Vowel spaces of the L1 and L2 vowels are plotted in Figure \ref{fig:six}. The finding that [ʊ] is higher than [ũ] is not unexpected, because nasalized vowels are often observed to have significantly lower F1 values \citep{Carignan_2017, Hawkins_1985}. 

Figure \ref{fig:six} also demonstrates that four of the five speech samples contain vowels that are quite different from the native norms. One L2 speech sample that contains a [i] that is spectrally very close to the mean of L1 [ɪ]s. A question remains as to why this specific L2 segment was perceived as a tensed vowel by SAA transcribers. Voice quality was found as a correlate of English tense/lax contrast. The following section measures voice quality of the L2 [i]. 

\paragraph{Voice Quality of [i]}

Formant information mainly approximates how the vocal tract modifies the sound made by the vocal folds.  The movement of vocal folds generates sounds that could be perceptually “breathier” or “creakier”. Both breathy and creaky voice could be produced with a certain amount of vocal fold vibration (i.e., voiced sounds). Compared to creaky voice, breathy voice is produced with a relatively larger space between the vocal fold (i.e., larger glottis opening). The difference in voice quality, such as “breathiness” or “creakiness”, is of some relevance to the distinction between English lax and tensed vowels. 

Research on English tense and lax vowels has shown that voice quality might be used to perceptually distinguish the English tense-lax contrast in the absence of F1/F2 difference \citep{Di_Paolo_1990, Lotto_1997}. More specifically, a high front vowel with more breathy quality is more likely to be perceived as the tense vowel /i/. 

To investigate whether voice quality has affected SAA transcribers’ perception of tensing, it is necessary to measure the voice quality of the lax vowel [ɪ] in “\textit{six}.” A reliable acoustic parameter for voice quality in many languages is spectral tilt, which measures the degree of amplitude change as frequency increases. Previous research has identified several acoustic parameters as measurements for voice quality \citep{Garellek_2019}. The current study opted to quantify spectral tilt by comparing the amplitude of the first harmonics (H1) to the second harmonics (H2), which is the most commonly used and typically most reliable measurement for voice quality.\footnote{Several studies reported that H1-H2 might not be reliable in nasal environments. See \citet{Garellek_2019} for a more thorough review} Breathy voice usually correlates with stronger amplitude on the lower harmonics and weaker amplitude on higher ones. Creaky voice is the opposite. Voice quality, therefore, is often measured by subtracting H2 from H1.

L1 and L2 speech samples of “\textit{six spoons}” were analyzed using the VoiceSauce package \citep{Shue_2011} in MatLab R2017b. The frequencies of harmonics and fundamental frequencies were estimated by the STRAIGHT algorithm \citep{Kawahara_2009}. The Snack Sound Toolkit \citep{Sjolander_2004} was used to locate the formants. 

\begin{figure}[ht]
  \figSpace
    \centering
  \input{figures/chp3/h1h2.tex}
  %\includegraphics[width=0.75\textwidth]{figures/phonation.png}
    \caption{Voice Quality Comparisons between L1 and L2 Productions of /ɪ/}
    \label{fig:h1h2}
  \figSpace
\end{figure}

Figure \ref{fig:h1h2} shows the average H1-H2 values of L1 and L2 segments. The three L2 speech samples involving the raising of [ɪ] in “\textit{six}” were all produced by females. Therefore, the comparison below illustrates only the difference between the three female L2 productions and all female L1 productions. As the figure shows, all three L2 speakers’ pronunciation had a relatively higher degree of breathiness (i.e., higher H1-H2 values) than the L1 speaker norm. The Serbian speaker’s production is less breathy than the other two L2 speakers; it is nevertheless breathier than the native mean. The fact that the SAA transcribers perceived high vowels with breathy quality as [i] is consistent with previous findings on the effect of voice quality on vowel height perception \citep{Lotto_1997}. The IPA transcriptions for these L2 speech samples were therefore accepted by the current study to represent vowel tensing. 



\subsection{Summary of Segmental Analysis}

The current study selected four types of L2 speech samples. Stimuli selection was based on IPA transcriptions available in the SAA. The most common L1 productions in the SAA were considered the L1 target productions. L2 speech samples that were transcribed the same as their L1 target productions were termed as the match stimuli. L2 speech samples whose IPA transcriptions differ from transcriptions of their L1 target productions were termed as the mismatch stimuli. The sections above described two types of mismatch stimuli. The first type consists of 25 L2 speech samples that were termed consonant mismatch. IPA transcriptions for these L2 speech samples differ from their L1 target productions by only one consonant. The second type consists of 25 L2 speech samples that were termed vowel mismatch. IPA transcriptions for these L2 speech samples differ from their L1 target productions by only one vowel. 

Acoustic analysis was conducted to examine the reliability of the IPA transcriptions. As shown in the analysis above, acoustic differences between the L2 speech samples and their corresponding L1 speech samples could be captured by IPA transcriptions of the L2 speech samples. The current study, therefore, considered these IPA transcriptions reliable. Audio files of these L2 speech samples were thus used by the current study as stimuli in two perception studies (Chapters 4 and 5). 

The third type of mismatch was termed syllable mismatch, because it concerns syllable structure differences between an L2 speech sample and its L1 target production. While consonant or vowel changes preserve the original syllable structure, segment deletion or segment epenthesis changes the original structure. The next section describes the selection of the 25 speech samples with syllable mismatches.

\subsection{Syllable Structures}

Structural variations investigated by the current study involve vowel epenthesis and consonant deletion. Co-articulatory properties and/or L1 phonotactics could, to some degree, generate a perceptual illusion of segment insertion, often termed as the “ghost segments” or “illusory segments” \citep{Dupoux_1999}. To select stimuli with potential structural problems, L2 audio samples were inspected in PRAAT to rule out possible cases of illusory perception. The following section uses two examples to illustrate how the inspections were carried out. As mentioned previously, the most common L1 productions in the SAA were considered representatives of L1 target productions. For example, the majority of the 100 surveyed L1 speakers of American English pronounced the word “\textit{ask}” in phrase “\textit{ask her}” as [æsk], while only one of the 100 L1 speakers pronounced the “\textit{ask}” as [æs]. [æsk] was therefore considered the L1 target production. [æs] was considered as a production with syllable mismatch. In other words, productions with mismatches are uncommon in L1 speech, but they are not necessarily unique to L2 speakers. 

To select L2 speech samples whose syllable structure differ from L1 target productions, the current study selected 25 L2 speech samples from the SAA based on their respective IPA transcriptions. To further inspect the reliability of the IPA transcriptions, acoustic information of the L2 speech samples were examined in PRAAT. If spectral information of a segment was missing from an L2 speech sample but existed in L1 target productions, then the L2 speech sample was considered as a stimulus with syllable mismatch. More specifically, it was considered a stimulus with segment deletion. Alternatively, if spectral information of a segment existed in an L2 speech sample but was missing from L1 target productions, then the L2 speech sample was considered as a stimulus with segment insertion.

\subsubsection{Segment Deletion}

Figure \ref{fig:del} shows the spectrogram of an L1 production and an L2 production of “\textit{ask her}”, where the dotted lines represent pitch contours and the solid lines represent intensity contours. The graph on the left illustrates an L1 production, which shows visible stop closure and burst after /s/. These characteristics are absent from the L2 production on the right, indicating that coda /k/ was dropped by the L2 speaker.

\begin{figure}[h!]
  \figSpace
    \centering
	\includegraphics[width=1\textwidth]{figures/chp3/kdel.eps}
    \caption{/k/-Deletion in “\textit{ask her}”}
    \label{fig:del}
  \figSpace
\end{figure}

\subsubsection{Segment Insertion}

Eight stimuli were included in the current study to represent three types of segment insertions. Two stimuli involved prothesis of s-clusters (i.e., [sp]$\rightarrow$[əsp] in “\textit{six spoons}”); three stimuli involved anaptyxis of /pl/-clusters (i.e., /pl/ to /pəl/ in “\textit{please call}”); two stimuli represent paragoge at the end of “\textit{ask}” (i.e., [æsk]$\rightarrow$[æskə]), and one stimulus represents paragoge at the end of “five” (i.e. [faɪv] to [faɪvə]). The SAA transcribers marked discourse fillers and epenthetic vowels differently. A space was added between discourse fillers and their adjacent segments (e.g., [æsk ə həɹ]). No space was added between epenthetic vowels and the segment they epenthesize to (e.g., [æskə həɹ]). Speech samples with discourse fillers were not selected. The eight stimuli all contain epenthetic vowels as indicated by their respective IPA transcriptions. 

Figure \ref{fig:epen} illustrates a case of paragoge. The speech sample was produced by a Korean speaker who inserted a /ə/-like vocoid at the end of the word “\textit{ask}.” The epenthesized vocoid was transcribed by the SAA transcribers as a [ə]. 

\begin{figure}[h!]
  \figSpace
    \centering
	\includegraphics[width=0.8\textwidth]{figures/chp3/insert.eps}
    \caption{Paragoge after “\textit{ask}”}
    \label{fig:epen}
  \figSpace
\end{figure}

Spectral inspection carried out by the current study has successfully identified the epenthesized vocoid because it shows clear formant structures, carries pitch, and contains an intensity peak. These characteristics were utilized in the inspection of all other cases of segment insertion. Of the eight cases inspected, seven of them satisfy the aforementioned criteria. The prothetic vocoid of /sp/ does not carry pitch, yet it contains clear formant structures and an intensity peak. One could argue against defining such vocoid, and indeed all the other seven vocoids, as epenthetic vowels. As previous research often shows, epenthetic vowels, transitional vowels and extended sonorants are sometimes difficult to distinguish, and definitions of epenthetic vowels vary from language to language \citep{Gouskova_2009, Hall_2011, Hall_2003}. 

The current study took an impressionistic approach with regard to vowel epenthesis. As long as the epenthesized segment has clear formant structure and was transcribed with a [ə] or [ɪ], it is considered an epenthetic vocoid.  In summary, IPA transcriptions of the 25 L2 speech samples were verified via the process discussed above. The 25 L2 speech samples were selected as stimuli with syllable mismatches. 

\section{Summary}

The current study selected 100 L2 speech samples as stimuli in two perception studies. The L2 speech samples were chosen based primarily on their IPA transcriptions in the SAA. To observe the potential effects of phonological context on accentedness perception, five phonological contexts from the so-called “Stella” passage were chosen. Each context was represented by 20 L2 speech samples, yielding 100 L2 speech samples in total. To determine the L1 target productions for the five contexts, IPA transcriptions of 100 L1 speakers of American English from the SAA were surveyed to find the most common productions (e.g., [pʰliz kʰɑl] for “\textit{please call}”). L2 speech samples that were transcribed the same as their L1 target productions were termed as the match stimuli. L2 speech samples that were not transcribed as the same as their L1 target productions were termed as the mismatch stimuli. 

Among the 20 L2 speech samples for each of the five contexts, five speech samples were the match stimuli (e.g., [pʰliz kʰɑl] for “\textit{please call}”). The rest 15 L2 speech samples were the mismatch stimuli. Among the 15 mismatch stimuli, five differed from their L1 target production by only one consonant (e.g., [pʰlis kʰɑl] for “\textit{please call}”), five differed from their L1target production by only one vowel (e.g., [pʰliz kʰol] for “\textit{please call}”). Another five L2 speech samples, did not differ from their L1 target production segmentally, but contained either one more or one less segment than their L1 target productions (e.g., [pʰəliz kʰɑl] or [pʰliz kʰɑ] for “\textit{please call}”). These three types of stimuli were termed consonant mismatch, vowel mismatch, and syllable mismatch respectively. 

To verify the reliability of the IPA transcriptions for the 100 L2 stimuli, acoustic analysis was performed to compare L2 speech samples with their L1 counterparts. Speech samples from 50 L1 speakers of American English were extracted from the SAA for the analysis of native speaker pronunciation norms, which were approximated by the mean L1 values of relevant benchmark acoustic measurements (e.g., mean L1 VOT duration, mean L1 COG, mean L1 F1/F2/F3 values etc.). Results showed that acoustic differences between the L2 stimuli and native speaker norms were successfully captured by the IPA transcriptions. The current study therefore concluded that these IPA transcriptions for the 100 L2 stimuli are reliable. These stimuli were then used in two perception studies to elicit accentedness judgment from L1 listeners of American English. 
































